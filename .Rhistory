main = "Model accuracy",
xlab = "Predictors",
ylab = "Accuracy")
plot(model.randForest)
plot(model.randForest,
main = "Model accuracy",
xlab = "Predictors",
ylab = "Accuracy")
model.randForest1 <- train(classe ~., method="rf", data=pml.training.train,ntree=150,prox=TRUE)
model.randForest1 <- train(classe ~., method="rf", data=pml.training.train,ntree=100,prox=TRUE)
model.randForest
library(caret)
library(randomForest)
library(rpart)
set.seed(8888)
train<-read.csv("pml-training.csv",na.strings=c("NA",""), strip.white = T)
test <-read.csv("pml-testing.csv", na.strings=c("NA",""), strip.white = T)
isNA.train <- apply(train, 2, function(x) { sum(is.na(x)) })
isNA.test <- apply(test, 2, function(x) { sum(is.na(x)) })
training <- subset(train[, which(isNA.train == 0)],
select=-c(X, user_name, new_window, num_window, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp))
testing <- subset(test[, which(isNA.test == 0)],
select=-c(X, user_name, new_window, num_window, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp))
pml.training.index <- createDataPartition(y=training$classe,p=0.6,list=FALSE)
pml.training.train <- training[pml.training.index,]
pml.training.test <- training[-pml.training.index,]
dim(pml.training.train)
dim(pml.training.test)
model.randForest1 <- train(classe ~., model=FALSE, method="rf", data=pml.training.train,ntree=100,prox=TRUE)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
data <- segmentationOriginal
set.seed(125)
inTrain <- data$Case == "Train"
trainData <- data[inTrain, ]
testData <- data[!inTrain, ]
cartModel <- train(Class ~ ., data=trainData, method="rpart")
cartModel$finalModel
plot(cartModel$finalModel, uniform=T)
text(cartModel$finalModel, cex=0.8)
plot(cartModel$finalModel, uniform=T)
text(cartModel$finalModel, cex=0.8)
library(pgmm)
data(olive)
dim(olive)
head(olive)
olive <- olive[,-1]
treeModel <- train(Area ~ ., data=olive, method="rpart2")
treeModel
newdata <- as.data.frame(t(colMeans(olive)))
predict(treeModel, newdata)
install.packages("pgmm")
library(pgmm)
data(olive)
dim(olive)
head(olive)
olive <- olive[,-1]
treeModel <- train(Area ~ ., data=olive, method="rpart2")
treeModel
newdata <- as.data.frame(t(colMeans(olive)))
predict(treeModel, newdata)
install.packages("ElemStateLearn")
install.packages("ElemStatLearn")
##Problem 4
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
logitModel <- train(chd ~ age + alcohol + obesity + tobacco +
typea + ldl, data=trainSA, method="glm",
family="binomial")
logitModel
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
predictTrain <- predict(logitModel, trainSA)
predictTest <- predict(logitModel, testSA)
# Training Set Misclassification rate
missClass(trainSA$chd, predictTrain) # 0.2727273
# Test Set Misclassification rate
missClass(testSA$chd, predictTest) # 0.3116883
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
head(vowel.train)
head(vowel.test)
dim(vowel.train) # 528  11
dim(vowel.test) # 462  11
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
model.randForest1 <- train(classe ~., model=FALSE, method="rf", data=pml.training.train,ntree=100)
confusionMatrix(pml.training.train$classe, predict(model.randForest1, pml.training.train))
plot(model.randForest, log = "y",
main = "Model accuracy",
xlab = "Predictors",
ylab = "Accuracy")
plot(model.randForest1, log = "y",
main = "Model accuracy",
xlab = "Predictors",
ylab = "Accuracy")
library(elasticnet)
install.packages("elasticnet")
##Problem 3
set.seed(3523)
library(AppliedPredictiveModeling)
library(elasticnet)
data(concrete)
inTrain <- createDataPartition(concrete$CompressiveStrength,
p=3/4)[[1]]
training <- concrete[inTrain, ]
testing <- concrete[-inTrain, ]
set.seed(233)
fit <- train(CompressiveStrength ~ ., data=training, method="lasso")
fit
plot.enet(fit$finalModel, xvar="penalty", use.color=T)
set.seed(3523)
library(AppliedPredictiveModeling)
library(elasticnet)
library(caret)
data(concrete)
inTrain <- createDataPartition(concrete$CompressiveStrength,
p=3/4)[[1]]
training <- concrete[inTrain, ]
testing <- concrete[-inTrain, ]
set.seed(233)
fit <- train(CompressiveStrength ~ ., data=training, method="lasso")
fit
plot.enet(fit$finalModel, xvar="penalty", use.color=T) # Cement
##problem4
library(lubridate)  # For year() function below
library(forecast)
dat <- read.csv("./data/gaData.csv")
training <- dat[year(dat$date) < 2012, ]
testing <- dat[(year(dat$date)) > 2011, ]
tstrain <- ts(training$visitsTumblr)
fit <- bats(tstrain)
fit
pred <- forecast(fit, level=95, h=dim(testing)[1])
names(data.frame(pred))
predComb <- cbind(testing, data.frame(pred))
names(testing)
names(predComb)
predComb$in95 <- (predComb$Lo.95 < predComb$visitsTumblr) &
(predComb$visitsTumblr < predComb$Hi.95)
# How many of the testing points is the true value within the
# 95% prediction interval bounds?
prop.table(table(predComb$in95))[2] # 0.9617021
install.packages("forecast")
library(lubridate)  # For year() function below
library(forecast)
dat <- read.csv("./data/gaData.csv")
training <- dat[year(dat$date) < 2012, ]
testing <- dat[(year(dat$date)) > 2011, ]
tstrain <- ts(training$visitsTumblr)
fit <- bats(tstrain)
fit
pred <- forecast(fit, level=95, h=dim(testing)[1])
names(data.frame(pred))
predComb <- cbind(testing, data.frame(pred))
names(testing)
names(predComb)
predComb$in95 <- (predComb$Lo.95 < predComb$visitsTumblr) &
(predComb$visitsTumblr < predComb$Hi.95)
# How many of the testing points is the true value within the
# 95% prediction interval bounds?
prop.table(table(predComb$in95))[2] # 0.9617021
library(lubridate)  # For year() function below
library(forecast)
dat <- read.csv("./data/gaData.csv")
training <- dat[year(dat$date) < 2012, ]
testing <- dat[(year(dat$date)) > 2011, ]
tstrain <- ts(training$visitsTumblr)
fit <- bats(tstrain)
fit
pred <- forecast(fit, level=95, h=dim(testing)[1])
names(data.frame(pred))
predComb <- cbind(testing, data.frame(pred))
names(testing)
names(predComb)
predComb$in95 <- (predComb$Lo.95 < predComb$visitsTumblr) &
(predComb$visitsTumblr < predComb$Hi.95)
# How many of the testing points is the true value within the
# 95% prediction interval bounds?
prop.table(table(predComb$in95))[2] # 0.9617021
library(lubridate)  # For year() function below
library(forecast)
dat <- read.csv("./data/gaData.csv")
training <- dat[year(dat$date) < 2012, ]
testing <- dat[(year(dat$date)) > 2011, ]
tstrain <- ts(training$visitsTumblr)
fit <- bats(tstrain)
fit
pred <- forecast(fit, level=95, h=dim(testing)[1])
names(data.frame(pred))
predComb <- cbind(testing, data.frame(pred))
names(testing)
names(predComb)
?forecast
install.packages("forecast")
install.packages("forecast")
library(lubridate)  # For year() function below
library(forecast)
library(forecast)
sessionInfo()
install.packages("forecast")
install.packages("forecast")
library(forecast)
install.packages("zoo")
install.packages("zoo")
install.packages("forecast")
library(forecast)
install.packages(timeDate)
install.packages("timeDate")
install.packages("timeDate")
library(forecast)
install.packages("forecast", dependencies = TRUE)
install.packages("forecast", dependencies = TRUE)
install.packages("forecast", dependencies = TRUE)
library(forecast)
install.packages("Rcpp")
install.packages("Rcpp")
install.packages("Rcpp")
install.packages("Rcpp")
install.packages("Rcpp")
install.packages("Rcpp")
install.packages("Rcpp")
library(forecast)
install.packages("Rcpp")
install.packages("forecast", dependencies = TRUE)
library(forecast)
library(forecast)
install.packages("forecast")
install.packages("RandomForest")
install.packages("randomForest")
install.packages("ggplot2")
install.packages("lattice")
library(forecast)
library(ggplot2)
qplot(disp, mpg, data=mtcars)
qplot(disp, mpg, data=mtcars, col= as.factor(cyl))
qplot(disp, mpg, data=mtcars, shape= as.factor(cyl))
qplot(disp, mpg, data=mtcars, size= as.factor(cyl))
rain<-read.csv("data/cityrain.csv")
plot(rain$Tokyo,type="b",lwd=2,
xaxt="n",ylim=c(0,300),col="black",
xlab="Month",ylab="Rainfall (mm)",
main="Monthly Rainfall in major cities")
axis(1,at=1:length(rain$Month),labels=rain$Month)
lines(rain$Berlin,col="red",type="b",lwd=2)
lines(rain$NewYork,col="orange",type="b",lwd=2)
lines(rain$London,col="purple",type="b",lwd=2)
legend("topright",legend=c("Tokyo","Berlin","New York","London"),
lty=1,lwd=2,pch=21,col=c("black","red","orange","purple"),
ncol=2,bty="n",cex=0.8,
text.col=c("black","red","orange","purple"),
inset=0.01)
rain
dp<-read.table("data\gdp_long.txt",header=T)
library(RColorBrewer)
pal<-brewer.pal(5,"Set1")
par(mar=par()$mar+c(0,0,0,2),bty="l")
plot(Canada~Year,data=gdp,type="l",lwd=2,lty=1,ylim=c(30,60),
col=pal[1],main="Percentage change in GDP",ylab="")
mtext(side=4,at=gdp$Canada[length(gdp$Canada)],text="Canada",
col=pal[1],line=0.3,las=2)
lines(gdp$France~gdp$Year,col=pal[2],lwd=2)
mtext(side=4,at=gdp$France[length(gdp$France)],text="France",
col=pal[2],line=0.3,las=2)
lines(gdp$Germany~gdp$Year,col=pal[3],lwd=2)
mtext(side=4,at=gdp$Germany[length(gdp$Germany)],text="Germany",
col=pal[3],line=0.3,las=2)
lines(gdp$Britain~gdp$Year,col=pal[4],lwd=2)
mtext(side=4,at=gdp$Britain[length(gdp$Britain)],text="Britain",
col=pal[4],line=0.3,las=2)
lines(gdp$USA~gdp$Year,col=pal[5],lwd=2)
mtext(side=4,at=gdp$USA[length(gdp$USA)]-2,
text="USA",col=pal[5],line=0.3,las=2)
gdp<-read.table("data/gdp_long.txt",header=T)
library(RColorBrewer)
pal<-brewer.pal(5,"Set1")
par(mar=par()$mar+c(0,0,0,2),bty="l")
plot(Canada~Year,data=gdp,type="l",lwd=2,lty=1,ylim=c(30,60),
col=pal[1],main="Percentage change in GDP",ylab="")
mtext(side=4,at=gdp$Canada[length(gdp$Canada)],text="Canada",
col=pal[1],line=0.3,las=2)
lines(gdp$France~gdp$Year,col=pal[2],lwd=2)
mtext(side=4,at=gdp$France[length(gdp$France)],text="France",
col=pal[2],line=0.3,las=2)
lines(gdp$Germany~gdp$Year,col=pal[3],lwd=2)
mtext(side=4,at=gdp$Germany[length(gdp$Germany)],text="Germany",
col=pal[3],line=0.3,las=2)
lines(gdp$Britain~gdp$Year,col=pal[4],lwd=2)
mtext(side=4,at=gdp$Britain[length(gdp$Britain)],text="Britain",
col=pal[4],line=0.3,las=2)
lines(gdp$USA~gdp$Year,col=pal[5],lwd=2)
mtext(side=4,at=gdp$USA[length(gdp$USA)]-2,
text="USA",col=pal[5],line=0.3,las=2)
rain<-read.csv("data/cityrain.csv")
plot(rain$Tokyo,type="b",lwd=2,
xaxt="n",ylim=c(0,300),col="black",
xlab="Month",ylab="Rainfall (mm)",
main="Monthly Rainfall in Tokyo")
axis(1,at=1:length(rain$Month),labels=rain$Month)
grid(nx=NA, ny=8,lwd=1,lty=2,col="blue")
grid(nx=NA, ny=10,lwd=1,lty=2,col="blue")
rain<-read.csv("data/cityrain.csv")
plot(rain$Tokyo,type="b",lwd=2,
xaxt="n",ylim=c(0,300),col="black",
xlab="Month",ylab="Rainfall (mm)",
main="Monthly Rainfall in Tokyo")
axis(1,at=1:length(rain$Month),labels=rain$Month)
grid(nx=NA, ny=10,lwd=1,lty=2,col="blue")
library("zoo")
library(zoo)
library(zoo)
sales<-read.csv("data/dailysales.csv")
plot(sales$units~as.Date(sales$date,"%d/%m/%y"),type="l",
xlab="Date",ylab="Units Sold")
plot(strptime(sales$date,"%d/%m/%Y"),sales$units,type="l",
xlab="Date",ylab="Units Sold")
plot(sales$units~as.Date(sales$date,"%d/%m/%y"),type="l",
xlab="Date",ylab="Units Sold")
plot(strptime(sales$date,"%d/%m/%Y"),sales$units,type="l",
xlab="Date",ylab="Units Sold")
plot(zoo(sales$units,as.Date(sales$date,"%d/%m/%y")))
air<-read.csv("data/openair.csv")
plot(air$nox~as.Date(air$date,"%d/%m/%Y %H:%M"),type="l",
xlab="Time", ylab="Concentration (ppb)",
main="Time trend of Oxides of Nitrogen")
main="Time trend of Oxides of Nitrogen")
plot(zoo(air$nox,as.Date(air$date,"%d/%m/%Y %H:%M")),
xlab="Time", ylab="Concentration (ppb)",
main="Time trend of Oxides of Nitrogen")
plot(air$nox~as.Date(air$date,"%d/%m/%Y %H:%M"),type="l",
xaxt="n",
xlab="Time", ylab="Concentration (ppb)",
main="Time trend of Oxides of Nitrogen")
xlabels<-strptime(air$date, format = "%d/%m/%Y %H:%M")
axis.Date(1, at=xlabels[xlabels$mday==1], format="%b-%Y")
plot(air$nox~as.Date(air$date,"%d/%m/%Y %H:%M"),type="l",
xlab="Time", ylab="Concentration (ppb)",
main="Time trend of Oxides of Nitrogen")
abline(v=as.Date("25/12/2003","%d/%m/%Y"))
plot(air$nox~as.Date(air$date,"%d/%m/%Y %H:%M"),type="l",
xlab="Time", ylab="Concentration (ppb)",
main="Time trend of Oxides of Nitrogen")
abline(v=as.Date("25/12/2003","%d/%m/%Y"),col=red)
plot(air$nox~as.Date(air$date,"%d/%m/%Y %H:%M"),type="l",
xlab="Time", ylab="Concentration (ppb)",
main="Time trend of Oxides of Nitrogen")
abline(v=as.Date("25/12/2003","%d/%m/%Y"),col="red")
install.packages("quantmod")
install.packages("tseries")
library(quantmod)
library(tseries)
aapl<-get.hist.quote(instrument = "aapl", quote = c("Cl", "Vol"))
goog <- get.hist.quote(instrument = "goog", quote = c("Cl", "Vol"))
msft <- get.hist.quote(instrument = "msft", quote = c("Cl", "Vol"))
plot(msft$Close,main = "Stock Price Comparison",
ylim=c(0,800), col="red", type="l", lwd=0.5,
pch=19,cex=0.6, xlab="Date" ,ylab="Stock Price (USD)")
lines(goog$Close,col="blue",lwd=0.5)
lines(aapl$Close,col="gray",lwd=0.5)
legend("top",horiz=T,legend=c("Microsoft","Google","Apple"),
col=c("red","blue","gray"),lty=1,bty="n")
getSymbols("AAPL",src="yahoo")
barChart(AAPL)
candleChart(AAPL,theme="white")
library(RColorBrewer)
citysales<-read.csv("citysales.csv")
citysales<-read.csv("data/citysales.csv")
barplot(as.matrix(citysales[,2:4]), beside=TRUE,
legend.text=citysales$City,
args.legend=list(bty="n",horiz=TRUE),
col=brewer.pal(5,"Set1"),
border="white",ylim=c(0,100),
ylab="Sales Revenue (1,000's of USD)",
main="Sales Figures")
box(bty=1)
box(bty="1")
barplot(as.matrix(citysales[,2:4]), beside=TRUE,
legend.text=citysales$City,
args.legend=list(bty="n",horiz=TRUE),
col=brewer.pal(5,"Set1"),
border="white",ylim=c(0,100),
ylab="Sales Revenue (1,000's of USD)",
main="Sales Figures")
box(bty="1")
?box
box(lty="solid")
barplot(as.matrix(citysales[,2:4]), beside=TRUE,
legend.text=citysales$City,
args.legend=list(bty="n",horiz=TRUE),
col=brewer.pal(5,"Set1"),
border="white",ylim=c(0,100),
ylab="Sales Revenue (1,000's of USD)",
main="Sales Figures")
box(lty="solid")
barplot(as.matrix(citysales[,2:4]),
legend.text=citysales$City,
args.legend=list(bty="n",horiz=TRUE),
col=brewer.pal(5,"Set1"),border="white",
ylim=c(0,200),ylab="Sales Revenue (1,000's of USD)",
main="Sales Figures")
barplot(as.matrix(citysales[,2:4]), beside=TRUE,horiz=TRUE,
legend.text=citysales$City, args.legend=list(bty="n"),
col=brewer.pal(5,"Set1"),border="white",
xlim=c(0,100), xlab="Sales Revenue (1,000's of USD)",
main="Sales Figures")
x<-barplot(as.matrix(citysales[,2:4]), beside=TRUE,
legend.text=citysales$City, args.legend=list(bty="n",horiz=TRUE),
col=brewer.pal(5,"Set1"),border="white",
ylim=c(0,100),ylab="Sales Revenue (1,000's of USD)",
main="Sales Figures")
y<-as.matrix(citysales[,2:4])
text(x,y+2,labels=as.character(y))
browsers<-read.table("data/browsers.txt",header=TRUE)
browsers<-browsers[order(browsers[,2]),]
pie(browsers[,2],
labels=browsers[,1],
clockwise=TRUE,
radius=1,
col=brewer.pal(7,"Set1"),
border="white",
main="Percentage Share of Internet Browser usage")
browser
browsers
pielabels <- sprintf("%s = %3.1f%s", browsers[,1],
100*browsers[,2]/sum(browsers[,2]), "%")
pie(browsers[,2],
labels=pielabels,
clockwise=TRUE,
radius=1,
col=brewer.pal(7,"Set1"),
border="white",
cex=0.8,
main="Percentage Share of Internet Browser usage")
pie(browsers[,2],
labels=pielabels,
clockwise=TRUE,
radius=1,
col=brewer.pal(7,"Set1"),
border="white",
cex=0.8,
main="Percentage Share of Internet Browser usage")
legend("bottomright",legend=pielabels,bty="n",
fill=brewer.pal(7,"Set1"))
pie(browsers[,2],
labels=NA,
clockwise=TRUE,
radius=0.7,
col=brewer.pal(7,"Set1"),
border="white",
cex=0.8,
main="Percentage Share of Internet Browser usage")
legend("bottomright",legend=pielabels,bty="n",
fill=brewer.pal(7,"Set1"))
install.packages("devtools")
devtools::install_github('rstudio/shinyapps')
devtools::install_github('ropensci/plotify')
devtools::install_github('ropensci/plotly')
install_github('slidify','ramnathv')
devtools::install_github('slidify','ramnathv')
devtools::install_github('slidifyLibraries','ramnathv')
library(shiny)
install.packages("shiny")
library(shiny)
runExample("01_Hello")
runExample("08_Hello")
runExample("08_html")
runApp("shiny_app1")
??reactive
library(shiny)
?reactive
runApp("Sample_Shiny2")
install.packages("googleVis")
runApp("Sample_Shiny2")
install.packages("reshape")
runApp("Sample_Shiny2")
runApp("Sample_Shiny2")
runApp("Sample_Shiny2")
runApp("Sample_xiaodan")
install.packages("rCharts")
library("rCharts")
??rCharts
update.packages("rCharts")
library("rCharts")
install.packages("rCharts")
runApp("sylvia_app")
runApp("sylvia_app")
runApp("sylvia_app")
install.packages("dplyr")
runApp("sylvia_app")
install.packages("DT")
runApp("sylvia_app")
runApp("sylvia_app")
install.packages("data.table")
runApp("sylvia_app")
shiny::runApp('sylvia_app')
shiny::runApp('sylvia_app')
impute.value <- function(steps,interval,IA.Data)
()
shiny::runApp('sylvia_app')
shiny::runApp('sylvia_app')
library(shiny)
shiny::runApp('sylvia_app')
shiny::runApp('sylvia_app')
